{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrapping NIVEL 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.- Extracción desde la nube con crawlera y Múltiples URLs semilla - URBANIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJETIVO**: \n",
    "\n",
    "    - Utilizar mas de una url semilla\n",
    "    - Aprender a utilizar Web Scraping en la Nube con CRAWLERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.item import Field, Item\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.loader.processors import MapCompose\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from scrapy.loader import ItemLoader\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Departamento(Item):\n",
    "    nombre = Field()\n",
    "    direccion = Field()\n",
    "    \n",
    "class Urbaniape(CrawlSpider):\n",
    "    custom_settings = {\n",
    "        'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36',\n",
    "        'CLOSESPIDER_ITEMCOUNT': 100,\n",
    "        'DOWNLOADER_MIDDLEWARES': {'scrapy_crawlera.CrawleraMiddleware': 610},\n",
    "        'CRAWLERA_ENABLED': True,\n",
    "        'CRAWLERA_APIKEY': 'INGRESA_TU_API_KEY generado en crawlera'\n",
    "    }\n",
    "    \n",
    "    start_urls = [\n",
    "      'https://urbania.pe/buscar/proyectos-propiedades?page=1',\n",
    "      'https://urbania.pe/buscar/proyectos-propiedades?page=2'\n",
    "    ] \n",
    "        \n",
    "    allowed_domains = ['urbania.pe']\n",
    "    download_delay = 1\n",
    "    \n",
    "    rules = (\n",
    "        Rule(\n",
    "            LinkExtractor(\n",
    "                allow = r'proyecto-'\n",
    "            ), follow = True, callback='parse_depa'),\n",
    "    )\n",
    "    \n",
    "    def parse_depa(self,response):\n",
    "        sel = Selector(response)\n",
    "        item = ItemLoader(Departamento(),sel)\n",
    "        item.add_xpath('nombre','//h2[@class=\"info-title\"]/text()')\n",
    "        item.add_xpath('direccion','//h2[@class=\"info-location\"]/text()')\n",
    "        \n",
    "        yield item.load_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-30 16:31:05 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
      "2020-12-30 16:31:05 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0\n",
      "2020-12-30 16:31:05 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2020-12-30 16:31:05 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'CLOSESPIDER_ITEMCOUNT': 5,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '\n",
      "               'like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 '\n",
      "               'Safari/537.36'}\n",
      "2020-12-30 16:31:06 [scrapy.extensions.telnet] INFO: Telnet Password: 9d3778d3cdd8a2f8\n",
      "2020-12-30 16:31:06 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.closespider.CloseSpider',\n",
      " 'scrapy.extensions.logstats.LogStats']\n"
     ]
    }
   ],
   "source": [
    "from scrapy.spiders import Spider\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "if __name__ == \"__main__\": # Código que se va a ejecutar al dar clic en RUN\n",
    "        process = CrawlerProcess()\n",
    "        process.crawl(Urbaniape) # Nombre de la clase de mi Spider\n",
    "        process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scrapy.crawler import CrawlerProcess\n",
    "#process = CrawlerProcess({\n",
    "#    'FEED_FORMAT':'csv',\n",
    "#    'FEED URI':'urbania.csv'\n",
    "#})\n",
    "\n",
    "#process.crawl(Urbaniape)\n",
    "#process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
